"""
Exploitability Validation Orchestrator

Executes the multi-stage validation pipeline with:
- Deterministic stage execution
- JSON schema validation
- Error recovery
- Progress tracking
"""

import os
import json
import logging
from pathlib import Path
from datetime import datetime
from dataclasses import dataclass, field
from typing import Optional, List, Dict, Any, Callable
from enum import Enum

from .schemas import (
    validate_checklist,
    validate_findings,
    validate_attack_tree,
    validate_attack_paths,
    validate_attack_surface,
    validate_findings_for_stage,
    create_empty_checklist,
    create_empty_findings,
    ValidationError
)

logger = logging.getLogger(__name__)


class Stage(Enum):
    """Pipeline stages."""
    INVENTORY = "0"
    ONESHOT = "A"
    PROCESS = "B"
    SANITY = "C"
    RULING = "D"
    FEASIBILITY = "E"


class StageStatus(Enum):
    """Status of a stage execution."""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    SKIPPED = "skipped"


# Alias map: any legacy/mixed-case variant → canonical snake_case.
# Add entries here when upstream producers use a different convention.
_STATUS_ALIASES = {
    # ALL_CAPS legacy (orchestrator pre-cleanup, LLM skill output, docs)
    "EXPLOITABLE": "exploitable",
    "CONFIRMED": "confirmed",
    "CONFIRMED_CONSTRAINED": "confirmed_constrained",
    "CONFIRMED_BLOCKED": "confirmed_blocked",
    "CONFIRMED_UNVERIFIED": "confirmed_unverified",
    "RULED_OUT": "ruled_out",
    "NOT_EXPLOITABLE": "unlikely",
    # Title-case legacy (old feasibility verdicts)
    "Exploitable": "exploitable",
    "Likely exploitable": "likely_exploitable",
    "Difficult": "difficult",
    "Unlikely": "unlikely",
    "Unknown": "unknown",
    "Likely": "likely_exploitable",
    # Passthrough — already canonical
    "exploitable": "exploitable",
    "confirmed": "confirmed",
    "confirmed_constrained": "confirmed_constrained",
    "confirmed_blocked": "confirmed_blocked",
    "confirmed_unverified": "confirmed_unverified",
    "ruled_out": "ruled_out",
    "likely_exploitable": "likely_exploitable",
    "difficult": "difficult",
    "unlikely": "unlikely",
    "unknown": "unknown",
}


def normalize_status(value: Optional[str]) -> Optional[str]:
    """Normalize any status/verdict string to canonical snake_case.

    Handles ALL_CAPS, Title Case, and snake_case inputs.
    Unknown values are lowercased with spaces replaced by underscores.
    Non-string inputs are coerced to string first.
    """
    if not value:
        return value
    if not isinstance(value, str):
        value = str(value)
    value = value.strip()
    if not value:
        return None
    canonical = _STATUS_ALIASES.get(value)
    if canonical:
        return canonical
    # Fallback: lowercase, replace spaces/hyphens with underscores
    return value.lower().replace(" ", "_").replace("-", "_")


def normalize_findings(data: dict) -> None:
    """Normalize all status/verdict fields in a findings dict in-place."""
    for finding in data.get("findings", []):
        if not isinstance(finding, dict):
            continue
        if finding.get("status"):
            finding["status"] = normalize_status(finding["status"])
        if finding.get("final_status"):
            finding["final_status"] = normalize_status(finding["final_status"])

        ruling = finding.get("ruling")
        if ruling and ruling.get("status"):
            ruling["status"] = normalize_status(ruling["status"])

        feasibility = finding.get("feasibility")
        if feasibility:
            if feasibility.get("verdict"):
                feasibility["verdict"] = normalize_status(feasibility["verdict"])
            if feasibility.get("status"):
                feasibility["status"] = normalize_status(feasibility["status"])


# Human-readable display for status values (per CLAUDE.md style guide)
STATUS_DISPLAY = {
    # Final statuses (snake_case → human-readable)
    "exploitable": "Exploitable",
    "confirmed_constrained": "Confirmed (constrained)",
    "confirmed_blocked": "Confirmed (blocked)",
    "confirmed": "Confirmed",
    "confirmed_unverified": "Confirmed (unverified)",
    # Validation statuses
    "pending": "Pending",
    "not_disproven": "Not disproven",
    "disproven": "Disproven",
    "ruled_out": "Ruled out",
    "poc_success": "PoC success",
    # Feasibility verdicts
    "likely_exploitable": "Likely exploitable",
    "difficult": "Difficult",
    "unlikely": "Unlikely",
    "unknown": "Unknown",
    # Stage statuses
    "analyzed": "Analyzed",
    "not_applicable": "Not applicable",
    "skipped": "Skipped",
    # Error states
    "error": "Error",
}


@dataclass
class StageResult:
    """Result of a stage execution."""
    stage: Stage
    status: StageStatus
    output_files: List[str] = field(default_factory=list)
    errors: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
    duration_seconds: float = 0.0
    retry_count: int = 0


@dataclass
class PipelineConfig:
    """Configuration for the validation pipeline."""
    target_path: str
    workdir: str
    vuln_type: Optional[str] = None
    binary_path: Optional[str] = None
    findings_file: Optional[str] = None  # Pre-existing findings to validate
    skip_feasibility: bool = False
    max_retries: int = 3
    validate_schemas: bool = True

    # Stage-specific config
    stage_b_max_attempts: int = 5  # Max attempts per attack path
    stage_b_proximity_threshold: int = 3  # Min proximity to continue


@dataclass
class PipelineState:
    """Current state of the pipeline."""
    config: PipelineConfig
    current_stage: Optional[Stage] = None
    stage_results: Dict[Stage, StageResult] = field(default_factory=dict)
    checklist: Optional[Dict] = None
    findings: Optional[Dict] = None
    attack_tree: Optional[Dict] = None
    attack_paths: Optional[List] = None
    attack_surface: Optional[Dict] = None
    hypotheses: Optional[List] = None
    disproven: Optional[List] = None
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None

    def get_output_path(self, filename: str) -> str:
        """Get full path for an output file."""
        return os.path.join(self.config.workdir, filename)

    def save_json(self, filename: str, data: Any) -> str:
        """Save data to JSON file in workdir."""
        if filename == "findings.json" and isinstance(data, dict):
            normalize_findings(data)
        path = self.get_output_path(filename)
        with open(path, 'w') as f:
            json.dump(data, f, indent=2, default=str)
        return path

    def load_json(self, filename: str) -> Any:
        """Load JSON file from workdir."""
        path = self.get_output_path(filename)
        if os.path.exists(path):
            try:
                with open(path, 'r') as f:
                    data = json.load(f)
            except json.JSONDecodeError as e:
                logger.warning(f"Invalid JSON in {filename}: {e}")
                return None
            # Normalize status fields in findings (LLM may write any case)
            if filename == "findings.json" and isinstance(data, dict):
                normalize_findings(data)
            return data
        return None


# Memory corruption types that require Stage E
MEMORY_CORRUPTION_TYPES = {
    'buffer_overflow', 'heap_overflow', 'stack_overflow',
    'format_string', 'use_after_free', 'double_free',
    'integer_overflow', 'out_of_bounds_read', 'out_of_bounds_write'
}


def normalize_rule_id(rule_id: str, tool_name: str) -> str:
    """
    Normalize verbose rule IDs to clean vulnerability types.

    Returns a value from the FINDING_SCHEMA vuln_type enum, falling back to
    'other' for unrecognized patterns.

    Examples:
        'engine.semgrep.rules.crypto.raptor.crypto.weak-hash.python' -> 'weak_crypto'
        'java/sql-injection' -> 'sql_injection'
        'CWE-89' -> 'sql_injection'
    """
    if not rule_id:
        return 'other'

    # Valid vuln_type values per FINDING_SCHEMA
    valid_vuln_types = {
        'command_injection', 'sql_injection', 'xss', 'path_traversal',
        'ssrf', 'deserialization', 'buffer_overflow', 'heap_overflow',
        'stack_overflow', 'format_string', 'use_after_free', 'double_free',
        'integer_overflow', 'out_of_bounds_read', 'out_of_bounds_write',
        'hardcoded_secret', 'weak_crypto', 'other',
    }

    # CWE mapping for common vulnerabilities (values must match schema enum)
    cwe_map = {
        'CWE-78': 'command_injection',
        'CWE-79': 'xss',
        'CWE-89': 'sql_injection',
        'CWE-90': 'other',  # LDAP injection
        'CWE-91': 'other',  # XML injection
        'CWE-94': 'command_injection',  # Code injection -> command_injection
        'CWE-119': 'buffer_overflow',
        'CWE-120': 'buffer_overflow',
        'CWE-121': 'stack_overflow',
        'CWE-122': 'heap_overflow',
        'CWE-125': 'out_of_bounds_read',
        'CWE-134': 'format_string',
        'CWE-190': 'integer_overflow',
        'CWE-200': 'other',  # Info disclosure
        'CWE-22': 'path_traversal',
        'CWE-327': 'weak_crypto',
        'CWE-328': 'weak_crypto',  # Weak hash -> weak_crypto
        'CWE-415': 'double_free',
        'CWE-416': 'use_after_free',
        'CWE-502': 'deserialization',
        'CWE-611': 'other',  # XXE
        'CWE-787': 'out_of_bounds_write',
        'CWE-918': 'ssrf',
    }

    # Check CWE mapping
    upper_id = rule_id.upper()
    for cwe, vuln_type in cwe_map.items():
        if cwe in upper_id:
            return vuln_type

    # Keyword mapping for common rule ID fragments
    keyword_map = {
        'sql_injection': 'sql_injection', 'sqli': 'sql_injection',
        'command_injection': 'command_injection', 'cmd_injection': 'command_injection',
        'os_command': 'command_injection', 'rce': 'command_injection',
        'xss': 'xss', 'cross_site': 'xss',
        'path_traversal': 'path_traversal', 'directory_traversal': 'path_traversal',
        'ssrf': 'ssrf', 'server_side_request': 'ssrf',
        'deserialization': 'deserialization', 'deserialize': 'deserialization',
        'buffer_overflow': 'buffer_overflow',
        'heap_overflow': 'heap_overflow',
        'stack_overflow': 'stack_overflow',
        'format_string': 'format_string',
        'use_after_free': 'use_after_free', 'uaf': 'use_after_free',
        'double_free': 'double_free',
        'integer_overflow': 'integer_overflow', 'int_overflow': 'integer_overflow',
        'out_of_bounds_read': 'out_of_bounds_read', 'oob_read': 'out_of_bounds_read',
        'out_of_bounds_write': 'out_of_bounds_write', 'oob_write': 'out_of_bounds_write',
        'hardcoded_secret': 'hardcoded_secret', 'hard_coded': 'hardcoded_secret',
        'weak_crypto': 'weak_crypto', 'weak_hash': 'weak_crypto',
        'weak_cipher': 'weak_crypto',
    }

    # Strip common prefixes
    prefixes_to_strip = [
        'engine.semgrep.rules.',
        'semgrep.',
        'codeql.',
        'rules.',
        'security.',
        'raptor.',
    ]

    clean = rule_id.lower()
    for prefix in prefixes_to_strip:
        if clean.startswith(prefix):
            clean = clean[len(prefix):]

    # Normalize separators and check keyword map
    normalized = clean.replace('/', '_').replace('.', '_').replace('-', '_')
    for keyword, vuln_type in keyword_map.items():
        if keyword in normalized:
            return vuln_type

    # Extract the meaningful part (usually the last segment)
    parts = clean.replace('/', '.').split('.')
    filter_out = {'python', 'java', 'javascript', 'c', 'cpp', 'go', 'ruby', 'php', 'crypto'}
    meaningful = [p for p in parts if p and p not in filter_out]

    if meaningful:
        candidate = meaningful[-1].replace('-', '_')
        if candidate in valid_vuln_types:
            return candidate
    # Unrecognized rule — return 'other' rather than arbitrary string
    return 'other'


def convert_sarif_result(result: Dict, idx: int, tool_name: str,
                         rules: Dict, seen_fingerprints: set) -> Optional[Dict]:
    """Convert a single SARIF result to internal finding format."""
    # Skip 'note' level findings (informational only)
    level = result.get('level', 'warning')
    if level == 'note':
        return None

    # Extract locations
    locations = result.get('locations', [])
    if not locations:
        return None

    loc = locations[0]
    if not isinstance(loc, dict):
        return None
    phys_loc = loc.get('physicalLocation', {})
    artifact = phys_loc.get('artifactLocation', {})
    region = phys_loc.get('region', {})

    # Normalize file path
    file_path = artifact.get('uri', '')
    if file_path.startswith('file://'):
        file_path = file_path[7:]

    if not file_path:
        return None

    line = region.get('startLine', 0)
    if line == 0:
        logger.debug(f"SARIF: Dropping result (no startLine) — rule={result.get('ruleId')}, file={file_path}")
        return None

    # Get rule ID and normalize to clean vuln_type
    rule_id = result.get('ruleId', 'unknown')
    vuln_type = normalize_rule_id(rule_id, tool_name)

    # Check fingerprint for deduplication (use normalized vuln_type)
    fingerprint = result.get('fingerprints', {}).get('primaryLocationLineHash')
    if not fingerprint:
        # Create our own fingerprint using normalized type for cross-tool dedup
        fingerprint = f"{file_path}:{line}:{vuln_type}"

    if fingerprint in seen_fingerprints:
        return None
    seen_fingerprints.add(fingerprint)

    # Extract function name from logical locations
    function = 'unknown'
    for log_loc in loc.get('logicalLocations', []):
        if log_loc.get('kind') in ('function', 'method', 'member'):
            function = log_loc.get('name', log_loc.get('fullyQualifiedName', 'unknown'))
            break

    # Get rule metadata for severity
    rule = rules.get(rule_id, {})
    severity = rule.get('properties', {}).get('security-severity', level)

    # Extract snippet
    snippet = region.get('snippet', {}).get('text', '')
    if not snippet:
        context = phys_loc.get('contextRegion', {})
        snippet = context.get('snippet', {}).get('text', '')

    finding = {
        'id': f"SARIF-{idx:04d}",
        'file': file_path,
        'line': line,
        'function': function,
        'vuln_type': vuln_type,
        'status': 'not_disproven',
        'message': (result.get('message', '') if isinstance(result.get('message'), str) else result.get('message', {}).get('text', ''))[:200],
        'tool': tool_name,
        'rule_id': rule_id,
        'severity': result.get('level', 'warning')
    }
    if snippet:
        finding['proof'] = {'vulnerable_code': snippet[:500]}
    return finding


def convert_sarif_data(sarif: Dict, target_path: str) -> Dict:
    """Convert SARIF format to internal findings format.

    Handles:
    - SARIF 2.0 and 2.1.0 formats
    - Multiple runs from different tools
    - Logical locations for function names
    - Fingerprints for deduplication
    - Malformed entries (skipped with warning)
    """
    findings_list = []
    seen_fingerprints = set()
    skipped = 0
    finding_idx = 0

    for run_idx, run in enumerate(sarif.get('runs', [])):
        tool_name = run.get('tool', {}).get('driver', {}).get('name', 'unknown')
        rules = {r.get('id'): r for r in run.get('tool', {}).get('driver', {}).get('rules', [])}

        for result in run.get('results', []):
            try:
                finding = convert_sarif_result(
                    result, finding_idx, tool_name, rules, seen_fingerprints
                )
                if finding:
                    findings_list.append(finding)
                    finding_idx += 1
            except Exception as e:
                skipped += 1
                logger.warning(f"Skipped malformed SARIF result: {e}")
                continue

    if skipped > 0:
        logger.warning(f"Skipped {skipped} malformed SARIF results")

    return {
        'stage': 'A',
        'timestamp': datetime.now().isoformat(),
        'target_path': target_path,
        'source': 'sarif',
        'findings': findings_list
    }


class ValidationOrchestrator:
    """
    Orchestrates the exploitability validation pipeline.

    Usage:
        config = PipelineConfig(
            target_path="/path/to/code",
            workdir=".out/exploitability-validation-20260122/",
            vuln_type="command_injection"
        )
        orchestrator = ValidationOrchestrator(config)
        result = orchestrator.run()
    """

    def __init__(self, config: PipelineConfig):
        self.config = config
        self.state = PipelineState(config=config)
        self.stage_handlers: Dict[Stage, Callable] = {
            Stage.INVENTORY: self._run_stage_0,
            Stage.ONESHOT: self._run_stage_a,
            Stage.PROCESS: self._run_stage_b,
            Stage.SANITY: self._run_stage_c,
            Stage.RULING: self._run_stage_d,
            Stage.FEASIBILITY: self._run_stage_e,
        }

    def run(self) -> PipelineState:
        """Run the full validation pipeline."""
        self.state.started_at = datetime.now()

        # Create workdir
        os.makedirs(self.config.workdir, exist_ok=True)

        # Determine starting stage
        if self.config.findings_file:
            # Load findings and create minimal checklist (skips full inventory)
            self._load_existing_findings()
            # Run Stage B (Process), C (Sanity), D (Ruling), E (Feasibility)
            # Skip Stage 0 (Inventory) and A (One-Shot) since findings already provided
            stages = [Stage.PROCESS, Stage.SANITY, Stage.RULING, Stage.FEASIBILITY]
            logger.info(f"Pre-existing findings provided - skipping Stage 0 and A")
        else:
            stages = list(Stage)

        # Execute stages
        for stage in stages:
            result = self._execute_stage(stage)
            self.state.stage_results[stage] = result

            if result.status == StageStatus.FAILED:
                logger.error(f"Stage {stage.name} failed: {result.errors}")
                break

            # Check if we should skip remaining stages
            if self._should_skip_remaining(stage, result):
                break

        self.state.completed_at = datetime.now()
        self._generate_report()

        return self.state

    def _execute_stage(self, stage: Stage) -> StageResult:
        """Execute a single stage with retry logic."""
        self.state.current_stage = stage
        logger.info(f"Starting Stage {stage.value}: {stage.name}")

        result = StageResult(stage=stage, status=StageStatus.RUNNING)
        start_time = datetime.now()

        for attempt in range(self.config.max_retries):
            result.retry_count = attempt
            try:
                handler = self.stage_handlers[stage]
                output_files = handler()
                result.output_files = output_files
                result.status = StageStatus.COMPLETED

                # Validate outputs if enabled
                if self.config.validate_schemas:
                    validation_errors = self._validate_stage_outputs(stage)
                    if validation_errors:
                        result.warnings.extend(validation_errors)

                break

            except Exception as e:
                error_msg = f"Attempt {attempt + 1}/{self.config.max_retries}: {str(e)}"
                result.errors.append(error_msg)
                logger.warning(error_msg)

                if attempt == self.config.max_retries - 1:
                    result.status = StageStatus.FAILED

        result.duration_seconds = (datetime.now() - start_time).total_seconds()
        return result

    def _run_stage_0(self) -> List[str]:
        """Stage 0: Inventory - Build checklist of functions."""
        from .checklist_builder import build_checklist

        checklist = build_checklist(
            self.config.target_path,
            self.config.workdir,
            exclude_patterns=["*_test.*", "test_*", "*_mock.*", "mock_*", "__tests__/", "tests/", "fixtures/"]
        )

        self.state.checklist = checklist
        path = self.state.get_output_path("checklist.json")

        logger.info(f"Stage 0 complete: {checklist['total_files']} files, {checklist['total_functions']} functions")
        return [path]

    def _run_stage_a(self) -> List[str]:
        """Stage A: One-Shot - Quick exploitability check."""
        if not self.state.checklist:
            self.state.checklist = self.state.load_json("checklist.json")

        findings = create_empty_findings("A", self.config.target_path, self.config.vuln_type)

        # This is where LLM analysis would be invoked
        # For now, create structure for LLM to fill
        findings["_instruction"] = (
            "Analyze each function in checklist.json for the target vulnerability type. "
            "For each candidate, attempt to verify exploitability and build a harmless PoC. "
            "Update status to: poc_success, not_disproven, or disproven."
        )

        self.state.findings = findings
        path = self.state.save_json("findings.json", findings)

        return [path]

    def _run_stage_b(self) -> List[str]:
        """Stage B: Process - Systematic analysis with attack trees."""
        if not self.state.findings:
            self.state.findings = self.state.load_json("findings.json")
        if not self.state.findings:
            raise ValueError("Stage B: No findings available — ensure Stage A has completed")

        # Validate findings have required fields for Stage B
        validate_findings_for_stage(self.state.findings.get("findings", []), "B")

        # Check if we have any "not_disproven" findings that need Stage B
        not_disproven = [f for f in self.state.findings.get("findings", [])
                        if f.get("status") == "not_disproven"]

        if not not_disproven:
            logger.info("Stage B: No 'not_disproven' findings, skipping")
            return []

        # Initialize working documents
        attack_tree = {
            "root": "Exploit vulnerability",
            "updated_at": datetime.now().isoformat(),
            "nodes": []
        }
        attack_paths = []
        attack_surface = {"sources": [], "sinks": [], "trust_boundaries": []}
        hypotheses = []
        disproven = []

        # Save initial structures (don't overwrite if already populated by LLM skill)
        artifact_defaults = [
            ("attack-tree.json", attack_tree),
            ("attack-paths.json", attack_paths),
            ("attack-surface.json", attack_surface),
            ("hypotheses.json", hypotheses),
            ("disproven.json", disproven),
        ]
        paths = []
        actual_data = {}
        for filename, default_data in artifact_defaults:
            existing = self.state.load_json(filename)
            if existing is None:
                paths.append(self.state.save_json(filename, default_data))
                actual_data[filename] = default_data
            else:
                paths.append(self.state.get_output_path(filename))
                actual_data[filename] = existing

        self.state.attack_tree = actual_data["attack-tree.json"]
        self.state.attack_paths = actual_data["attack-paths.json"]
        self.state.attack_surface = actual_data["attack-surface.json"]
        self.state.hypotheses = actual_data["hypotheses.json"]
        self.state.disproven = actual_data["disproven.json"]

        disk_attack_paths = self.state.attack_paths  # already loaded above
        disk_hypotheses = self.state.hypotheses       # already loaded above

        for finding in self.state.findings.get("findings", []):
            if finding.get("status") != "not_disproven":
                continue

            matching_path = next(
                (p for p in disk_attack_paths if p.get("finding_id") == finding["id"]),
                None
            )

            # Don't overwrite feasibility that's already been processed
            existing_feas = finding.get("feasibility")
            if existing_feas and existing_feas.get("status") not in (None, "pending"):
                if matching_path and not existing_feas.get("attack_path_ref"):
                    existing_feas["attack_path_ref"] = f"attack-paths.json#{matching_path['id']}"
                continue

            confirmed_hypotheses = [
                h["hypothesis"] for h in disk_hypotheses
                if h.get("finding_id") == finding["id"]
                and h.get("status") == "confirmed"
            ]

            finding["feasibility"] = {
                "status": "pending",
                "chain_breaks": matching_path.get("blockers", []) if matching_path else [],
                "what_would_help": confirmed_hypotheses,
                "attack_path_ref": f"attack-paths.json#{matching_path['id']}" if matching_path else None,
            }

        # Validate attack_path_ref references resolve
        attack_paths_data = self.state.attack_paths or []
        attack_path_ids = {p.get("id") for p in attack_paths_data if isinstance(p, dict)}
        for finding in self.state.findings.get("findings", []):
            feas = finding.get("feasibility") or {}
            ref = feas.get("attack_path_ref")
            if ref and "#" in ref:
                _, path_id = ref.split("#", 1)
                if path_id not in attack_path_ids:
                    logger.warning(
                        f"Stage B: Dangling attack_path_ref '{ref}' in {finding.get('id')} "
                        f"— referenced path not found in attack-paths.json"
                    )
                    feas["attack_path_ref"] = None

        # Update findings
        self.state.findings["stage"] = "B"
        self.state.findings["timestamp"] = datetime.now().isoformat()
        paths.append(self.state.save_json("findings.json", self.state.findings))

        return paths

    def _run_stage_c(self) -> List[str]:
        """Stage C: Sanity - Verify findings against actual code."""
        if not self.state.findings:
            self.state.findings = self.state.load_json("findings.json")
        if not self.state.findings:
            raise ValueError("Stage C: No findings available — ensure previous stages have completed")

        # Validate findings have required fields for Stage C
        validate_findings_for_stage(self.state.findings.get("findings", []), "C")

        # Add sanity check instruction
        self.state.findings["_instruction"] = (
            "For each finding, verify against actual code: "
            "1. File exists at stated path "
            "2. Code matches VERBATIM at stated line "
            "3. Source->sink flow is real "
            "4. Code is reachable (function is called). "
            "Update sanity_check field for each finding."
        )

        self.state.findings["stage"] = "C"
        self.state.findings["timestamp"] = datetime.now().isoformat()
        path = self.state.save_json("findings.json", self.state.findings)

        return [path]

    def _run_stage_d(self) -> List[str]:
        """Stage D: Ruling - Filter findings based on practical criteria."""
        if not self.state.findings:
            self.state.findings = self.state.load_json("findings.json")
        if not self.state.findings:
            raise ValueError("Stage D: No findings available — ensure previous stages have completed")

        # Validate findings have required fields for Stage D
        validate_findings_for_stage(self.state.findings.get("findings", []), "D")

        # Only process findings that passed sanity check
        for finding in self.state.findings.get("findings", []):
            prior_status = finding.get("status")
            sanity = finding.get("sanity_check") or {}
            if sanity.get("passed") is False:
                finding["status"] = "ruled_out"
                finding["final_status"] = "ruled_out"
                finding["ruling"] = {
                    "status": "ruled_out",
                    "prior_status": prior_status,
                    "disqualifier": "sanity_check_failed",
                    "reason": "Failed sanity check in Stage C"
                }
            elif sanity.get("passed") is True:
                finding["status"] = "confirmed"
                finding["final_status"] = "confirmed"
                finding["ruling"] = {
                    "status": "confirmed",
                    "prior_status": prior_status,
                    "reason": "Passed sanity check in Stage C"
                }
            else:
                # No sanity check performed — still confirm for Stage E, but flag for review
                finding["status"] = "confirmed"
                finding["final_status"] = "confirmed"
                finding["ruling"] = {
                    "status": "confirmed",
                    "prior_status": prior_status,
                    "reason": "No sanity check performed - requires manual review"
                }

        self.state.findings["stage"] = "D"
        self.state.findings["timestamp"] = datetime.now().isoformat()
        path = self.state.save_json("findings.json", self.state.findings)

        return [path]

    def _run_stage_e(self) -> List[str]:
        """Stage E: Feasibility - Binary constraint analysis for memory corruption."""
        if not self.state.findings:
            self.state.findings = self.state.load_json("findings.json")
        if not self.state.findings:
            raise ValueError("Stage E: No findings available — ensure previous stages have completed")

        if self.config.skip_feasibility:
            logger.info("Stage E: Skipped (--skip-feasibility)")
            return []

        # Validate findings have required fields for Stage E
        validate_findings_for_stage(self.state.findings.get("findings", []), "E")

        # Check if any findings need feasibility analysis
        confirmed = [f for f in self.state.findings.get("findings", [])
                    if (f.get("ruling") or {}).get("status") == "confirmed"]

        memory_corruption_findings = [
            f for f in confirmed
            if f.get("vuln_type") in MEMORY_CORRUPTION_TYPES
        ]

        if not memory_corruption_findings:
            logger.info("Stage E: No memory corruption findings, skipping")
            self._finalize_non_memory_findings(confirmed)
            self.state.save_json("findings.json", self.state.findings)
            return [self.state.get_output_path("findings.json")]

        # Try to run exploit feasibility
        user_provided_binary = bool(self.config.binary_path)
        binary_path = self.config.binary_path

        # If user provided a binary path, check it exists
        if user_provided_binary and not Path(binary_path).exists():
            logger.warning(f"Stage E: Provided binary not found: {binary_path}")
            for f in memory_corruption_findings:
                existing = f.get("feasibility") or {}
                f["final_status"] = "confirmed_unverified"
                f["feasibility"] = {
                    **existing,
                    "status": "error",
                    "error": f"Provided binary not found: {binary_path}"
                }
            binary_path = None
        elif not user_provided_binary:
            # Try to auto-detect binary (no warning if not found)
            binary_path = self._find_binary()
            if not binary_path:
                logger.info("Stage E: No binary provided, skipping feasibility analysis")
                for f in memory_corruption_findings:
                    existing = f.get("feasibility") or {}
                    f["final_status"] = "confirmed_unverified"
                    f["feasibility"] = {
                        **existing,
                        "status": "skipped",
                        "reason": "No binary provided - use --binary to enable Stage E"
                    }

        if not binary_path:
            self._finalize_non_memory_findings(confirmed)
            self.state.findings["stage"] = "E"
            self.state.findings["timestamp"] = datetime.now().isoformat()
            self.state.save_json("findings.json", self.state.findings)
            return [self.state.get_output_path("findings.json")]
        else:
            # Import and run exploit feasibility
            try:
                from packages.exploit_feasibility import (
                    analyze_binary,
                    save_exploit_context
                )

                context_file_abs = save_exploit_context(binary_path)
                # Store as relative path from workdir for portability
                try:
                    context_file = os.path.relpath(context_file_abs, self.config.workdir)
                except ValueError:
                    context_file = context_file_abs  # Cross-drive on Windows

                for finding in memory_corruption_findings:
                    try:
                        result = analyze_binary(binary_path, vuln_type=finding.get("vuln_type"))

                        raw_verdict = normalize_status(result.get("verdict", "unknown"))

                        # Merge with existing feasibility from Stage B
                        existing = finding.get("feasibility") or {}
                        binary_breaks = result.get("blockers", [])
                        source_breaks = existing.get("chain_breaks", [])
                        # Prefix source vs binary breaks to avoid contradictions
                        tagged_source = [f"[source] {b}" if not b.startswith("[") else b for b in source_breaks]
                        tagged_binary = [f"[binary] {b}" if not b.startswith("[") else b for b in binary_breaks]
                        merged_breaks = list(dict.fromkeys(tagged_binary + tagged_source))

                        binary_helps = result.get("suggestions", [])
                        source_helps = existing.get("what_would_help", [])
                        merged_helps = list(dict.fromkeys(binary_helps + source_helps))

                        # Handle error verdicts separately
                        is_error = raw_verdict == "error" or result.get("error")
                        status = "error" if is_error else "analyzed"

                        # Preserve key analysis fields from the full result
                        analysis_data = {}
                        for key in (
                            "protections", "glibc_version", "glibc_n_disabled",
                            "glibc_mitigations", "kernel_mitigations",
                            "constraints", "payload_constraints", "exploit_primitives",
                            "exploitation_paths", "rop_gadgets", "elf_structure",
                            "input_handlers", "format_string_context",
                            "input_constraint_analysis", "libc_fingerprinting",
                            "libc", "summary", "raw_checksec",
                        ):
                            if key in result:
                                analysis_data[key] = result[key]

                        finding["feasibility"] = {
                            **existing,
                            "status": status,
                            "binary_path": binary_path,
                            "context_file": context_file,
                            "verdict": raw_verdict,
                            "chain_breaks": merged_breaks,
                            "what_would_help": merged_helps,
                            "binary_analysis": analysis_data,
                        }

                        # Capture error details when present
                        if is_error:
                            finding["feasibility"]["error"] = result.get("error", result.get("summary", "Unknown error"))

                        # Set final status based on verdict
                        verdict_to_status = {
                            "exploitable": "exploitable",
                            "likely_exploitable": "likely_exploitable",
                            "difficult": "confirmed_constrained",
                            "unlikely": "confirmed_blocked",
                            "unknown": "confirmed_unverified",
                            "error": "confirmed_unverified",
                        }
                        if raw_verdict not in verdict_to_status:
                            logger.warning(
                                f"Stage E: Unexpected verdict '{raw_verdict}' for "
                                f"{finding.get('id')}, defaulting to confirmed_unverified"
                            )
                        finding["final_status"] = verdict_to_status.get(
                            raw_verdict, "confirmed_unverified"
                        )
                    except Exception as e:
                        logger.error(f"Feasibility analysis failed for {finding.get('id')}: {e}")
                        existing = finding.get("feasibility") or {}
                        finding["final_status"] = "confirmed_unverified"
                        finding["feasibility"] = {
                            **existing,
                            "status": "error",
                            "error": str(e)
                        }

            except ImportError:
                affected_ids = [f.get("id", "?") for f in memory_corruption_findings]
                logger.warning(
                    f"exploit_feasibility package not available — "
                    f"{len(affected_ids)} findings affected: {', '.join(affected_ids)}"
                )
                print("⚠️  Stage E: exploit_feasibility not available, skipping binary analysis")
                for f in memory_corruption_findings:
                    existing = f.get("feasibility") or {}
                    f["final_status"] = "confirmed_unverified"
                    f["feasibility"] = {
                        **existing,
                        "status": "error",
                        "error": f"exploit_feasibility package not available (finding {f.get('id')})"
                    }

        self._finalize_non_memory_findings(confirmed)

        self.state.findings["stage"] = "E"
        self.state.findings["timestamp"] = datetime.now().isoformat()
        path = self.state.save_json("findings.json", self.state.findings)

        return [path]

    def _derive_verdict_from_source(self, feasibility: dict) -> str:
        """Derive a verdict from source-level analysis when no binary is available."""
        chain_breaks = feasibility.get("chain_breaks", [])
        what_would_help = feasibility.get("what_would_help", [])
        if chain_breaks and what_would_help:
            return "difficult"
        if chain_breaks and not what_would_help:
            return "unlikely"
        if not chain_breaks and what_would_help:
            # No breaks found, but unknowns remain — not fully confirmed
            return "difficult"
        if not chain_breaks and not what_would_help:
            return "likely_exploitable"
        return "unknown"

    def _finalize_non_memory_findings(self, confirmed: list) -> None:
        """Mark non-memory-corruption findings as confirmed with derived verdicts."""
        verdict_mapping = {
            "exploitable": "exploitable",
            "likely_exploitable": "likely_exploitable",
            "difficult": "confirmed_constrained",
            "unlikely": "confirmed_blocked",
        }
        for f in confirmed:
            if f.get("vuln_type") in MEMORY_CORRUPTION_TYPES:
                continue
            existing = f.get("feasibility") or {}
            # Preserve findings already analyzed with a verdict
            if existing.get("status") == "analyzed" and existing.get("verdict"):
                f["final_status"] = verdict_mapping.get(existing["verdict"], "confirmed")
                continue
            has_source_analysis = (
                existing.get("status") == "pending"
                or existing.get("chain_breaks")
                or existing.get("what_would_help")
            )
            if has_source_analysis:
                verdict = self._derive_verdict_from_source(existing)
                f["feasibility"] = {**existing, "status": "analyzed", "verdict": verdict}
                f["final_status"] = verdict_mapping.get(verdict, "confirmed")
            else:
                f["feasibility"] = {"status": "not_applicable"}
                f["final_status"] = "confirmed"

    def _find_binary(self) -> Optional[str]:
        """Attempt to find compiled binary in common build output locations.

        Searches up to 3 levels deep in standard build directories.
        """
        target = Path(self.config.target_path)
        max_depth = 3

        # Common build output locations (checked in priority order)
        search_roots = [
            target / "build",
            target / "bin",
            target / "out",
            target / "dist",
            target / "cmake-build-debug",
            target / "cmake-build-release",
            target,
        ]

        searched = []
        for root in search_roots:
            if not root.exists():
                continue
            searched.append(str(root))
            # Depth-limited recursive search
            try:
                for f in root.rglob("*"):
                    # Limit depth: count path components relative to root
                    try:
                        rel = f.relative_to(root)
                        if len(rel.parts) > max_depth:
                            continue
                    except ValueError:
                        continue
                    if f.is_file() and os.access(f, os.X_OK):
                        # Skip common non-binary executables
                        if f.suffix in ('.py', '.sh', '.bash', '.pl', '.rb', '.js'):
                            continue
                        logger.info(f"Stage E: Auto-detected binary: {f}")
                        return str(f)
            except PermissionError:
                continue

        if searched:
            logger.warning(f"Stage E: No binary found in: {', '.join(searched)}")
        return None

    def _validate_stage_outputs(self, stage: Stage) -> List[str]:
        """Validate stage outputs against schemas."""
        errors = []

        if stage == Stage.INVENTORY and self.state.checklist:
            valid, errs = validate_checklist(self.state.checklist)
            if not valid:
                errors.extend([f"checklist.json: {e}" for e in errs])

        if stage in (Stage.ONESHOT, Stage.PROCESS, Stage.SANITY, Stage.RULING, Stage.FEASIBILITY):
            if self.state.findings:
                valid, errs = validate_findings(self.state.findings)
                if not valid:
                    errors.extend([f"findings.json: {e}" for e in errs])

        if stage == Stage.PROCESS:
            if self.state.attack_tree:
                valid, errs = validate_attack_tree(self.state.attack_tree)
                if not valid:
                    errors.extend([f"attack-tree.json: {e}" for e in errs])

            if self.state.attack_paths:
                valid, errs = validate_attack_paths(self.state.attack_paths)
                if not valid:
                    errors.extend([f"attack-paths.json: {e}" for e in errs])

            if self.state.attack_surface:
                valid, errs = validate_attack_surface(self.state.attack_surface)
                if not valid:
                    errors.extend([f"attack-surface.json: {e}" for e in errs])

        return errors

    def _should_skip_remaining(self, stage: Stage, result: StageResult) -> bool:
        """Check if remaining stages should be skipped."""
        if stage == Stage.ONESHOT:
            # If all findings are disproven, skip remaining
            findings = self.state.findings.get("findings", []) if self.state.findings else []
            if findings and all(f.get("status") == "disproven" for f in findings):
                logger.info("All findings disproven in Stage A, pipeline complete")
                return True

        if stage == Stage.RULING:
            # If no confirmed findings, skip Stage E
            findings = self.state.findings.get("findings", []) if self.state.findings else []
            confirmed = [f for f in findings if (f.get("ruling") or {}).get("status") == "confirmed"]
            if not confirmed:
                logger.info("No confirmed findings after Stage D, pipeline complete")
                return True

        return False

    def _load_existing_findings(self):
        """Load pre-existing findings file (JSON or SARIF format)."""
        try:
            with open(self.config.findings_file, 'r') as f:
                data = json.load(f)
        except json.JSONDecodeError as e:
            logger.error(f"Invalid JSON in findings file: {e}")
            raise ValidationError(f"Failed to parse findings file: {e}")
        except FileNotFoundError:
            raise ValidationError(f"Findings file not found: {self.config.findings_file}")

        # Detect SARIF format and convert
        if self._is_sarif_format(data):
            self.state.findings = convert_sarif_data(data, self.config.target_path)
            logger.info(f"Converted SARIF: {len(self.state.findings.get('findings', []))} findings")
        else:
            self.state.findings = data
            normalize_findings(self.state.findings)
            valid, errs = validate_findings(self.state.findings)
            if not valid:
                logger.warning(f"Findings file has schema issues: {errs}")
            logger.info(f"Loaded JSON: {len(self.state.findings.get('findings', []))} findings")

        # Deduplicate findings
        self._deduplicate_findings()

        # Create minimal checklist from findings files
        self._create_minimal_checklist()

    def _is_sarif_format(self, data: Dict) -> bool:
        """Detect if data is SARIF format (supports 2.0 and 2.1)."""
        if not isinstance(data, dict):
            return False
        # SARIF 2.1.0 has $schema, SARIF 2.0 may not
        if 'runs' in data:
            schema = data.get('$schema', '')
            version = data.get('version', '')
            return ('sarif' in schema.lower() or
                    version.startswith('2.') or
                    isinstance(data.get('runs'), list))
        return False

    def _deduplicate_findings(self):
        """Deduplicate findings by file:line:type."""
        if not self.state.findings:
            return

        findings = self.state.findings.get('findings', [])
        if not findings:
            return

        seen = set()
        unique = []

        for finding in findings:
            key = (
                finding.get('file', ''),
                finding.get('line', 0),
                finding.get('vuln_type', '')
            )
            if key not in seen:
                seen.add(key)
                unique.append(finding)

        if len(unique) < len(findings):
            logger.info(f"Deduplicated: {len(findings)} -> {len(unique)} findings")
            self.state.findings['findings'] = unique

    def _create_minimal_checklist(self):
        """Create a minimal checklist from just the files in findings."""
        if not self.state.findings:
            return

        # Extract unique files from findings
        files = set()
        for finding in self.state.findings.get('findings', []):
            file_path = finding.get('file', '')
            if file_path:
                # Normalize path
                if file_path.startswith('file://'):
                    file_path = file_path[7:]
                files.add(file_path)

        # Create minimal checklist
        self.state.checklist = {
            'generated_at': datetime.now().isoformat(),
            'target_path': self.config.target_path,
            'total_files': len(files),
            'total_functions': len(self.state.findings.get('findings', [])),
            'scope': 'findings_only',
            'files': [{'path': f, 'language': 'unknown', 'functions': []} for f in sorted(files)]
        }

        # Save checklist
        path = self.state.save_json('checklist.json', self.state.checklist)
        logger.info(f"Created minimal checklist: {len(files)} files from findings")

    def _generate_report(self):
        """Generate final validation report."""
        report_lines = [
            "# Exploitability Validation Report",
            "",
            "## Summary",
            f"- Target: {self.config.target_path}",
            f"- Vulnerability Type: {self.config.vuln_type or 'all'}",
            f"- Started: {self.state.started_at}",
            f"- Completed: {self.state.completed_at}",
            "",
            "## Stage Results",
            ""
        ]

        for stage, result in self.state.stage_results.items():
            status_icon = {
                StageStatus.COMPLETED: "[OK]",
                StageStatus.FAILED: "[FAIL]",
                StageStatus.SKIPPED: "[SKIP]"
            }.get(result.status, "[?]")

            report_lines.append(f"- Stage {stage.value} ({stage.name}): {status_icon} ({result.duration_seconds:.1f}s)")
            if result.errors:
                for err in result.errors:
                    report_lines.append(f"  - Error: {err}")
            if result.warnings:
                for warn in result.warnings:
                    report_lines.append(f"  - Warning: {warn}")

        # Findings summary
        if self.state.findings:
            findings = self.state.findings.get("findings", [])
            report_lines.extend([
                "",
                "## Findings Summary",
                f"- Total: {len(findings)}",
            ])

            by_status = {}
            for f in findings:
                status = f.get("final_status") or f.get("status", "unknown")
                by_status[status] = by_status.get(status, 0) + 1

            for status, count in sorted(by_status.items()):
                display_status = STATUS_DISPLAY.get(status, status)
                report_lines.append(f"- {display_status}: {count}")

            # List confirmed findings
            confirmed = [f for f in findings if f.get("final_status") in
                        ("exploitable", "confirmed_constrained", "confirmed_blocked",
                         "confirmed", "confirmed_unverified")]

            if confirmed:
                report_lines.extend(["", "## Confirmed Findings", ""])
                for f in confirmed:
                    report_lines.append(f"### {f['id']}: {f['vuln_type']} in {f['file']}:{f['line']}")
                    report_lines.append(f"- Function: {f['function']}")
                    final_status = f.get('final_status', 'N/A')
                    report_lines.append(f"- Final Status: {STATUS_DISPLAY.get(final_status, final_status)}")

                    if (f.get("feasibility") or {}).get("verdict"):
                        verdict_raw = f['feasibility']['verdict']
                        report_lines.append(f"- Feasibility: {STATUS_DISPLAY.get(verdict_raw, verdict_raw)}")
                        if f['feasibility'].get('chain_breaks'):
                            report_lines.append(f"- Chain Breaks: {', '.join(f['feasibility']['chain_breaks'][:3])}")

                    report_lines.append("")

        # Coverage
        if self.state.checklist:
            total = self.state.checklist.get("total_functions", 0)
            checked = sum(1 for f in self.state.checklist.get("files", [])
                         for fn in f.get("functions", []) if fn.get("checked"))
            report_lines.extend([
                "## Coverage",
                f"- Functions checked: {checked}/{total}",
                ""
            ])

        report_path = self.state.get_output_path("validation-report.md")
        with open(report_path, 'w') as f:
            f.write('\n'.join(report_lines))

        logger.info(f"Report written to {report_path}")


def run_validation(
    target_path: str,
    vuln_type: str = None,
    binary_path: str = None,
    findings_file: str = None,
    skip_feasibility: bool = False,
    workdir: str = None
) -> PipelineState:
    """
    Convenience function to run the validation pipeline.

    Args:
        target_path: Path to code to analyze
        vuln_type: Vulnerability type to focus on (optional)
        binary_path: Path to compiled binary for Stage E (optional)
        findings_file: Pre-existing findings to validate (optional)
        skip_feasibility: Skip Stage E even for memory corruption
        workdir: Output directory (auto-generated if not provided)

    Returns:
        PipelineState with all results
    """
    if not workdir:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        workdir = f".out/exploitability-validation-{timestamp}"

    config = PipelineConfig(
        target_path=target_path,
        workdir=workdir,
        vuln_type=vuln_type,
        binary_path=binary_path,
        findings_file=findings_file,
        skip_feasibility=skip_feasibility
    )

    orchestrator = ValidationOrchestrator(config)
    return orchestrator.run()
